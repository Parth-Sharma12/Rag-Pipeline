{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9da84034",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "970fb344",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ASUS\\Desktop\\RAG-Data_ingestion\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "###DATA LOADING MODULE###\n",
    "from langchain_core.documents import Document\n",
    "from langchain_community.document_loaders import TextLoader\n",
    "from langchain_community.document_loaders import DirectoryLoader\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain_community.document_loaders import DirectoryLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80d78d8d",
   "metadata": {},
   "source": [
    "Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81657185",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import chromadb\n",
    "from chromadb.config import Settings\n",
    "import uuid\n",
    "from typing import List, Dict,Tuple, Any\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import os\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9637145",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EmbeddingModel:\n",
    "    \"\"\" Class to handle text embeddings using SentenceTransformer.\n",
    "\n",
    "        Args:\n",
    "            model_name (str): Name of the pre-trained model to use. Defaults to 'all-MiniLM-L6-v2'.\n",
    "    \"\"\"\n",
    "    def __init__(self, model_name: str = \"all-MiniLM-L6-v2\"):\n",
    "        self.model_name = model_name\n",
    "        self.model = None\n",
    "        self._load_model() ## we write protected method to load the model. this method is not accessible outside the class.\n",
    "    \n",
    "    def _load_model(self):\n",
    "        \"\"\"Load the SentenceTransformer model.\"\"\"\n",
    "        try:\n",
    "            self.model = SentenceTransformer(self.model_name)\n",
    "            print(f\"Loaded model: {self.model_name}\")\n",
    "            print(f\"model_dimension: {self.model.get_sentence_embedding_dimension()}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading model {self.model_name}: {e}\")\n",
    "            raise e\n",
    "\n",
    "    \n",
    "    def parse_documents(self,path: str) -> List[Document]:\n",
    "        \"\"\"Parse documents from the given directory.\n",
    "\n",
    "            Args:\n",
    "                path (str): Path to the directory containing text files.\n",
    "        \"\"\"\n",
    "        if not os.path.isdir(path):\n",
    "            raise ValueError(f\"Provided path {path} is not a valid directory.\")\n",
    "        \n",
    "        loader = DirectoryLoader(path, glob=\"*.pdf\", loader_cls=PyMuPDFLoader)\n",
    "        documents = loader.load()\n",
    "        return documents\n",
    "    \n",
    "    def batch_embed_texts(self, texts: List[str], batch_size: int = 32) -> np.ndarray:\n",
    "        \"\"\"Embed texts in batches to handle large datasets.\n",
    "\n",
    "            Args:\n",
    "                texts (List[str]): List of texts to be embedded.\n",
    "                batch_size (int): Size of each batch. Defaults to 32.\n",
    "        \"\"\"\n",
    "        if not self.model:\n",
    "            raise ValueError(\"Model not loaded.\")\n",
    "        \n",
    "        embeddings =[]\n",
    "        for i in range(0,len(texts),batch_size):\n",
    "            batch_texts = texts[i:i+batch_size]\n",
    "            batch_embeddings = self.model.encode(batch_texts, convert_to_numpy=True)\n",
    "            embeddings.append(batch_embeddings)\n",
    "        return np.vstack(embeddings)\n",
    "    \n",
    "    def chunking(self, path:str, chunk_size: int = 500, overlap: int = 50) -> Tuple[List[Document], np.ndarray]:\n",
    "        \"\"\"Chunk the text into smaller pieces.\n",
    "\n",
    "            Args:\n",
    "                text (str): The text to be chunked.\n",
    "                chunk_size (int): The size of each chunk. Defaults to 500.\n",
    "                overlap (int): The number of overlapping characters between chunks. Defaults to 50.\n",
    "\n",
    "            Returns:\n",
    "                List[str]: List of text chunks.\n",
    "        \"\"\"\n",
    "        All_texts = self.parse_documents(path) ## It will bydefault only split page content and not metadata.\n",
    "        text_splitter = RecursiveCharacterTextSplitter( \n",
    "            chunk_size=chunk_size,\n",
    "            chunk_overlap=overlap,\n",
    "            separators=[\"\\n\\n\", \"\\n\", \" \", \"\"]\n",
    "        )\n",
    "        chunks = text_splitter.split_documents(All_texts)\n",
    "        embedding = self.batch_embed_texts([chunk.page_content for chunk in chunks])\n",
    "        return chunks, embedding\n",
    "        \n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c43fc2e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VectorDB:\n",
    "\n",
    "    def __init__(self,collection_name:str = \"documents\"):\n",
    "        self.collection_name = collection_name\n",
    "        self.client = None\n",
    "        self.collection = None\n",
    "        self.persist_directory = \"/content/chroma_db\"\n",
    "        self._initialize_client()\n",
    "\n",
    "    def _initialize_client(self):\n",
    "        try:\n",
    "            os.makedirs(self.persist_directory, exist_ok=True)\n",
    "            self.client = chromadb.PersistentClient(path = self.persist_directory)\n",
    "            self.collection = self.client.get_or_create_collection(name=self.collection_name)\n",
    "            print(f\"ChromaDB client initialized with collection: {self.collection_name}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error initializing ChromaDB client: {e}\")\n",
    "            raise e\n",
    "\n",
    "    def add_documents(self, documents: List[Any], embeddings: np.ndarray):\n",
    "        if not self.collection:\n",
    "            raise ValueError(\"ChromaDB client not initialized.\")\n",
    "        if(len(documents) != len(embeddings)):\n",
    "            raise ValueError(\"Number of documents and embeddings must match.\")\n",
    "\n",
    "        ids = [str(uuid.uuid4()) for _ in range(len(documents))]\n",
    "        metadatas = [doc.metadata for doc in documents]\n",
    "        texts = [doc.page_content for doc in documents]\n",
    "\n",
    "        self.collection.add(\n",
    "            ids=ids,\n",
    "            metadatas=metadatas,\n",
    "            documents=texts,\n",
    "            embeddings=embeddings.tolist()  ## ChromaDB requires list of lists\n",
    "        )\n",
    "        print(f\"Added {len(documents)} documents to the collection {self.collection_name}.\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d0d52ff",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'EmbeddingModel' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m embedding_model = \u001b[43mEmbeddingModel\u001b[49m()\n\u001b[32m      2\u001b[39m chunks, embeddings_ = embedding_model.chunking(\u001b[33m\"\u001b[39m\u001b[33m../data/pdfFiles\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mNameError\u001b[39m: name 'EmbeddingModel' is not defined"
     ]
    }
   ],
   "source": [
    "#Embedding Object\n",
    "embedding_model = EmbeddingModel()\n",
    "chunks, embeddings_ = embedding_model.chunking(\"../data/pdfFiles\")\n",
    "\n",
    "#VectorDB Object\n",
    "vectorStore = VectorDB()\n",
    "vectorStore.add_documents(chunks, embeddings_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "721fcc75",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "459905d1",
   "metadata": {},
   "source": [
    "Retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47a3ce2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ChromaRetriever:\n",
    "    \"\"\"Retriever for querying documents stored in ChromaDB\"\"\"\n",
    "\n",
    "    def __init__(self, vector_store, top_k: int = 5):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            vector_store: Instance of VectorStore (ChromaDB wrapper)\n",
    "            top_k: Number of top results to retrieve\n",
    "        \"\"\"\n",
    "        self.vector_store = vector_store\n",
    "        self.top_k = top_k\n",
    "\n",
    "    def retrieve(self, query: str):\n",
    "        \"\"\"Retrieve top-k documents for a query string\"\"\"\n",
    "        if not self.vector_store.collection:\n",
    "            raise ValueError(\"ChromaDB collection not initialized.\")\n",
    "\n",
    "        results = self.vector_store.collection.query(\n",
    "            query_texts=[query],  # the search query\n",
    "            n_results=self.top_k   # number of documents to return\n",
    "        )\n",
    "        return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4ac3385",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = ChromaRetriever(vectorStore, top_k=3)\n",
    "\n",
    "# 4. Query\n",
    "query = \"Write your query here\"\n",
    "embed_query = embedding_model.batch_embed_texts(query)\n",
    "results = retriever.retrieve(query)\n",
    "\n",
    "# 5. Print results\n",
    "for doc, meta in zip(results[\"documents\"][0], results[\"metadatas\"][0]):\n",
    "    print(f\"Content: {doc[:200]}...\\nMetadata: {meta}\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "RAG-Data_ingestion",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
